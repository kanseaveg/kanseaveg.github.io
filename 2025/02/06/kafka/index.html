



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Kanseaveg's Domain" href="https://blog.chatdb.cc/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Kanseaveg's Domain" href="https://blog.chatdb.cc/atom.xml" />
<link rel="alternate" type="application/json" title="Kanseaveg's Domain" href="https://blog.chatdb.cc/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  

<link rel="canonical" href="https://blog.chatdb.cc/2025/02/06/kafka/">



  <title>
Kafka Notes |
Kanseaveg's Domain</title>
<meta name="generator" content="Hexo 7.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">Kafka Notes
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2025-02-06 15:25:32">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2025-02-06T15:25:32+08:00">2025-02-06</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">Kanseaveg's Domain</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002325745.jpg"></li>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002749268.jpg"></li>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002941020.jpg"></li>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002146729.jpg"></li>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002252783.jpg"></li>
          <li class="item" data-background-image="https://raw.githubusercontent.com/euanpic8888/images/main/20250207002409679.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="https://blog.chatdb.cc/2025/02/06/kafka/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="Euan Cai">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Kanseaveg's Domain">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="kafka"><a class="markdownIt-Anchor" href="#kafka">#</a> kafka</h1>
<h2 id="是什么"><a class="markdownIt-Anchor" href="#是什么">#</a> 是什么</h2>
<p>Kafka 是一种分布式、高吞吐量的分布式发布订阅消息系统</p>
<h2 id="为什么需要"><a class="markdownIt-Anchor" href="#为什么需要">#</a> 为什么需要</h2>
<ol>
<li>缓冲和削峰</li>
<li>解耦重要业务流程</li>
<li>异步通信</li>
</ol>
<h2 id="集群部署"><a class="markdownIt-Anchor" href="#集群部署">#</a> 集群部署</h2>
<ol>
<li>下载对应的 kafka 安装包</li>
<li>修改 config 下的 server.properties:<br>
a. <span class="exturl" data-url="aHR0cDovL2Jyb2tlci5pZA==">broker.id</span><br>
b. log.dirs<br>
c. zookeeper.connect</li>
<li>在各个机器上启动 kafka：bin/kafka-sever-start.sh -daemon config/server.properties</li>
<li>配置集群启停脚本</li>
</ol>
<h2 id="交互命令"><a class="markdownIt-Anchor" href="#交互命令">#</a> 交互命令</h2>
<ol>
<li><span class="exturl" data-url="aHR0cDovL2thZmthLXRvcGljcy5zaA==">kafka-topics.sh</span> --bootstrap-server hadoop102:9092<br>
a. list all topic:  --list<br>
b. create topic: --create --partitions 1 --replication-factor 3 --topic first<br>
c. delete topic: --delete --topic first<br>
d. describe topic: --describe --topic first<br>
e. alter topic: --alter–topic first --partitions 3</li>
<li>producer/consumer --bootstrap-server hadoop102:9092<br>
a. send message: --topic first<br>
b. consume message: --from-beginning --topic first</li>
</ol>
<h1 id="kafka-的架构"><a class="markdownIt-Anchor" href="#kafka-的架构">#</a> kafka 的架构</h1>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250206184652.png" alt="20250206184652"></p>
<ol>
<li>Producer/Consumer: 生产者 / 消费者</li>
<li>Consumer Group: 消费者组，负责消费来自不同分区的数据，一个分区只能由一个消费者组消费</li>
<li>Broker: 代理人，一台 kafka 服务器就是一个 broker，一个 broker 包含多个 topic</li>
<li>Topic: 主题，用于存储数据</li>
<li>Partition: 分区，一个 Topic 可以分为多个 Partition 分区，每个分区内数据有序</li>
<li>Replica: 副本，每个 partition 分区都有一个 leader 副本和多个 follower 副本</li>
<li>Zookeeper: 协调器，记录 broker 服务器的运行状态以及不同分区之间的 leader 和 follower 信息</li>
</ol>
<h1 id="kafka-生产者"><a class="markdownIt-Anchor" href="#kafka-生产者">#</a> kafka 生产者</h1>
<h2 id="生产者发送消息原理"><a class="markdownIt-Anchor" href="#生产者发送消息原理">#</a> 生产者发送消息原理</h2>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207012841.png" alt="20250207012841"></p>
<p>发送消息时，会启动 main 进程和 sender 进程：</p>
<ol>
<li>main 线程负责生产数据：<br>
a. 创建 Producer 对象<br>
 b. 执行 0.send (ProducerRecord)<br>
 c. 经过 1. 拦截器进行必要处理<br>
 d. 利用 2. 序列化器对消息进行序列化<br>
 e. 利用 3. 分区器将消息划分到不同的消息队列中<br>
 f. kafka 使用双端队列（队列大小默认 32M，每批次 16k），一边塞消息一边发消息</li>
<li>sender 线程负责发送数据<br>
 a. 从双端队列中拉取数据<br>
 b. 使用 NetworkClient 与不同的 broker 建立连接<br>
 c. 基于 selector 将数据发送到不同的分区上（默认只能发送 5 个未接收 ack 应答的数据，超时会发送，默认 0ms，超 batch_size 也会发送，默认 16k）<br>
d. 并接收来自 broker 的应答，应答 ack=0 表示接收到数据不等落盘直接应答，ack=1 表示 leader 收到数据后应答，ack=-1/all 表示 leader 和 isr 队列都收到数据后应答</li>
</ol>
<h2 id="生产者发送时的分区策略"><a class="markdownIt-Anchor" href="#生产者发送时的分区策略">#</a> 生产者发送时的分区策略</h2>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207094842.png" alt="20250207094842"><br>
 默认采用 DefaultPartitioner：  实现 Partitioner 接口</p>
<ol>
<li>指明了 partition，则使用指明值</li>
<li>未指明 partition，则使用 key 的 hash% 分区值</li>
<li>未指明 partition 和 key，则使用粘性分区（随机选定一个分区一直用直到满）</li>
</ol>
<p>自定义分区，实现 Partitioner 接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(...)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">msgValue</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="keyword">if</span> (msgValue.contains(<span class="string">&quot;atguigu&quot;</span>)) partition = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span> partition = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="生产者发送吞吐量提升方法"><a class="markdownIt-Anchor" href="#生产者发送吞吐量提升方法">#</a> 生产者发送吞吐量提升方法</h2>
<p>即 NetworkClient 从双端队列中拉取消息的吞吐量，如何提升？</p>
<ol>
<li>提高拉取批次大小 batch.size</li>
<li>修改等待时间 <span class="exturl" data-url="aHR0cDovL2xpbmdlci5tcw==">linger.ms</span></li>
<li>修改数据压缩算法 snappy</li>
<li>修改缓存区大小 recordaccumulator</li>
</ol>
<h2 id="生产者如何保证数据可靠性ack应答级别"><a class="markdownIt-Anchor" href="#生产者如何保证数据可靠性ack应答级别">#</a> 生产者如何保证数据可靠性（ACK 应答级别）</h2>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207094948.png" alt="20250207094948"></p>
<p>producer 向集群发送数据，有三种 ack 级别：</p>
<ol>
<li>对于 ack=0，leader 不等待马上应答，若 leader 突然挂了，followers 都拷贝不到数据，存在丢数风险</li>
<li>对于 ack=1，leader 收到数据后应答，若 leader 突然挂了，followers 依旧无法拷贝到数据，存在丢数风险</li>
<li>对于 ack=-1，leader 和 followers 们收到数据后应答，leader 和 followers 都有数据，若此时一个 follower 突然挂了，leader 无法向发送方发送全部收到的 ack，因此：<br>
a. kafka 设计了一个动态的 ISR（in-sync replica set），用来动态维护同步的 foller+leader 集合（isr: 0,1,2; leader: 0），ack=-1 负责与 ISR 列表中的节点进行应答确认<br>
 b. isr 中若一个 follower 长时间未与 leader 通信，则被踢出这个 ISR 列表，默认 30s<br>
c. isr 中若所有的 follower 都挂了，则退化成 ack=1，又存在丢数风险<br>
 d. 因此，数据完全可靠条件 = ack=-1 + 分区副本数 &gt;=2 + ISR 里最小副本数 &gt;=2
<blockquote>
<p>分区副本数 &gt;=2：即 isr 中至少存在一个 leader 副本和 follower 副本<br>
 ISR 里最小副本数 &gt;=2: 亦如此，此条件用于约束 follower 也在 isr 中<br>
若在发送确认 ack 之前，leader 突然挂了，则需要重新选举 leader，此时新选举的 leader 应该如何处理重复数据？</p>
</blockquote>
</li>
</ol>
<h2 id="生产者如何保证数据去重"><a class="markdownIt-Anchor" href="#生产者如何保证数据去重">#</a> 生产者如何保证数据去重</h2>
<h3 id="数据幂等性"><a class="markdownIt-Anchor" href="#数据幂等性">#</a> 数据幂等性</h3>
<p>数据传递语义<br>
● 至少一次：ack=-1 + 分区副本数 &gt;=2 + ISR 应答最小副本数 &gt;=2   =&gt; 会重复，但保证数据不丢<br>
● 最多一次：ack=0                                         =&gt; 不会重复，但会丢数据<br>
● 精确一次：ack=-1 + 幂等性                               =&gt; 引入幂等性和事务，从而保证数据不丢也不重复<br>
○ 即无论接受到多少重复数据，broker 只持久化一条，根据 key 值 &lt;ProducerId, Partition, SeqNumber&gt; 判断是否重复，且只能保证单分区单会话内不重复，默认开启幂等性</p>
<h3 id="生产者事务"><a class="markdownIt-Anchor" href="#生产者事务">#</a> 生产者事务</h3>
<p>由于幂等性只能保证单分区单会话内不重复，因此需要引入事务，从而保证跨分区跨会话不重复，只能使用事务确保</p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207145445.png" alt="20250207145445"></p>
<ol>
<li>每个 broker 上都有  事务协调器， 事务信息特殊主题，  分区副本 leader</li>
<li>在使用事务前，<span class="exturl" data-url="aHR0cDovL3huLS1Qcm9kdWNlcnRyYW5zYWN0aW9uLW42NzNhaHpwdGk1NmN4bjJkeWY2bS5pZA==">Producer 先自定义一个 transaction.id</span></li>
<li>事务划分根据 transaction.id 的 hashcode%50 计算出事务使用哪儿个分区，对应分区的 leader 副本所在的 broker 的事务协调器就是此次事务的话事人</li>
<li>提交事务时，producer 向协调器请求 ProducerId，并将数据发送到分区副本 leader 对应的 topic 中，并向协调器发送 commit 请求</li>
<li>commit 请求的消息会持久化到事务信息特殊主题中，成功之后会给 topic 发送 commit 请求，判断数据真正写入到 topic 中</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3. 创建 Kafka 生产者（配置事务支持所需的属性）</span></span><br><span class="line">  KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line">  properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;transaction_id_0&quot;</span>); <span class="comment">// 设置事务 id（必须），事务 id 任意起名</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">      kafkaProducer.initTransactions(); <span class="comment">// 初始化事务（必须先于任何事务操作调用）</span></span><br><span class="line">      kafkaProducer.beginTransaction();  <span class="comment">// 开启一个新事务</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123; <span class="comment">// 4. 批量发送消息（在事务中）</span></span><br><span class="line">          <span class="comment">// 构建消息记录（主题，消息内容）</span></span><br><span class="line">          ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i);</span><br><span class="line">          kafkaProducer.send(record);   <span class="comment">// 异步发送消息（可添加回调函数处理发送结果）</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// int i = 1 / 0;  // 模拟异常（测试事务回滚时可取消注释）</span></span><br><span class="line">      kafkaProducer.commitTransaction(); <span class="comment">// 提交事务（只有当所有消息成功发送时才会执行）</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      kafkaProducer.abortTransaction();</span><br><span class="line">      System.err.println(<span class="string">&quot;Transaction aborted: &quot;</span> + e.getMessage());    <span class="comment">// 发生异常时终止事务（自动回滚未提交的消息）</span></span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      kafkaProducer.close();    <span class="comment">// 5. 确保最终关闭生产者（会等待所有未完成操作完成）</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h1 id="kafka-broker"><a class="markdownIt-Anchor" href="#kafka-broker">#</a> kafka broker</h1>
<p>在 kafka 中如何存储数据的，以及如何和 zk 沟通的</p>
<h2 id="kafka-broker工作流程"><a class="markdownIt-Anchor" href="#kafka-broker工作流程">#</a> kafka broker 工作流程</h2>
<h3 id="zk中存储的kafka信息"><a class="markdownIt-Anchor" href="#zk中存储的kafka信息">#</a> zk 中存储的 kafka 信息</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207162920.png" alt="20250207162920"></p>
<ol>
<li>broker_ids [0,1,2] 有哪儿些服务器</li>
<li>leader_id  {“leader”:1,“isr”:[0,1,2]} 谁是 leader</li>
<li>controller {“候选 leader”: 0} 在 leader 挂了之后，成为接任 leader 候选之一</li>
</ol>
<h3 id="broker与zk协调的总体工作流程"><a class="markdownIt-Anchor" href="#broker与zk协调的总体工作流程">#</a> broker 与 zk 协调的总体工作流程</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207163609.png" alt="20250207163609"></p>
<ol>
<li>三个节点向 zk 注册</li>
<li>哪儿台 broker 的 controller 先向 zk 注册，哪儿台 broker 的 controller 说了算</li>
<li>controller 按照选举规则选举出 leader（以 isr 节点存活为前提，优先选举 ar 中排在前面的），并将信息同步到 zk 中</li>
<li>其他节点的 controller 从 zk 同步相关信息</li>
<li>假设选举出来的 leader 挂了，zk 的 controller 会监听到变化，执行重新选举流程</li>
</ol>
<h2 id="节点服役与退役"><a class="markdownIt-Anchor" href="#节点服役与退役">#</a> 节点服役与退役</h2>
<h3 id="broker服役与退役"><a class="markdownIt-Anchor" href="#broker服役与退役">#</a> broker 服役与退役</h3>
<p>其实服役与退役的本质就是副本的迁移，若服役则将已有副本迁移到新节点，若退役则将已有副本迁移到其他节点</p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207164554.png" alt="20250207164554"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">服役 hadoop105</span></span><br><span class="line">bin/kafka-server-start.sh -daemon ./config/server.properties # hadoop105</span><br><span class="line"></span><br><span class="line">vim topics-to-move.json   # hadoop102</span><br><span class="line">&#123;&quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;first&quot;&#125;]&#125;</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2,3&quot; --generate # hadoop102</span><br><span class="line"></span><br><span class="line">vim increase-replication-factor.json # hadoop102,将上面返回的json内容Proposed partition reassignment configuration填入</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replic</span><br><span class="line">as&quot;:[2,3,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;par</span><br><span class="line">tition&quot;:1,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;to</span><br><span class="line">pic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;</span><br><span class="line">any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --reassignment-json-file increase-replication-factor.json --execute # hadoop102，执行迁移</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute # hadoop102，验证</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退役 hadoop105</span></span><br><span class="line">vim topics-to-move.json # hadoop105</span><br><span class="line">&#123;&quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;first&quot;&#125;], &quot;version&quot;: 1&#125;</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2&quot; --generate # hadoop102</span><br><span class="line"></span><br><span class="line">vim increase-replication-factor.json # hadoop102,同上，将返回的json内容填入</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute # hadoop102，执行迁移</span><br><span class="line"></span><br><span class="line">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --verify # hadoop102，验证</span><br><span class="line"></span><br><span class="line">bin/kafka-server-stop.sh # hadoop105，退役</span><br></pre></td></tr></table></figure>
<h3 id="章节小结"><a class="markdownIt-Anchor" href="#章节小结">#</a> 章节小结</h3>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXZyNHkxNjc3az9zcG1faWRfZnJvbT0zMzMuNzg4LnBsYXllci5zd2l0Y2gmYW1wO3ZkX3NvdXJjZT0xN2E1Mzk4MDg2NDU1ZjdmMWQwMDdkZjM4MmVhYjM5NSZhbXA7cD0yOQ==">章节小结</span></p>
<h2 id="kafka-副本"><a class="markdownIt-Anchor" href="#kafka-副本">#</a> kafka 副本</h2>
<p>kafka 所有的副本叫做 AR（Assigned Replicas），AR = ISR + OSR，从 ISR 中踢出去的就放到 OSR 里面</p>
<h3 id="leader选举流程演示"><a class="markdownIt-Anchor" href="#leader选举流程演示">#</a> leader 选举流程（演示）</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207171519.png" alt="20250207171519"></p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207171913.png" alt="20250207171913"></p>
<h3 id="follower故障处理演示"><a class="markdownIt-Anchor" href="#follower故障处理演示">#</a> follower 故障处理（演示）</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207172116.png" alt="20250207172116"></p>
<p>follower 故障：<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207172245.png" alt="20250207172245"></p>
<p>follower 归队：（向高水位靠齐）<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207172349.png" alt="20250207172349"></p>
<h3 id="leader故障处理演示"><a class="markdownIt-Anchor" href="#leader故障处理演示">#</a> leader 故障处理（演示）</h3>
<p>leader 挂了：<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207172445.png" alt="20250207172445"></p>
<p>新 leader 上位：（所有 follower 向 leader 低水位靠齐）<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207172550.png" alt="20250207172550"></p>
<h2 id="kafka-文件存储"><a class="markdownIt-Anchor" href="#kafka-文件存储">#</a> kafka 文件存储</h2>
<h3 id="文件存储机制"><a class="markdownIt-Anchor" href="#文件存储机制">#</a> 文件存储机制</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207181456.png" alt="20250207181456"></p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207181925.png" alt="20250207181925"></p>
<p>kafka 的索引是稀疏索引，每存储 4kb 的文件，才会往 index 中记录一条索引</p>
<h3 id="文件清理"><a class="markdownIt-Anchor" href="#文件清理">#</a> 文件清理</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207182451.png" alt="20250207182451"></p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207182505.png" alt="20250207182505"></p>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207182515.png" alt="20250207182515"></p>
<h2 id="kafka如何实现高效读写"><a class="markdownIt-Anchor" href="#kafka如何实现高效读写">#</a> kafka 如何实现高效读写</h2>
<ol>
<li>kafka 本身是分布式集群，可以采用分区技术，并行度高</li>
<li>读数据采用稀疏索引，可以快速定位要消费的数据</li>
<li>顺序写磁盘，日志一直追加写到文件末端</li>
<li>采用页缓存 + 零拷贝技术 （封装了 OS 底层的页缓存技术，消息无需落盘至应用层就被拷贝走了，即零拷贝）<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207183042.png" alt="20250207183042"></li>
</ol>
<h1 id="kafka消费者"><a class="markdownIt-Anchor" href="#kafka消费者">#</a> kafka 消费者</h1>
<h2 id="消费方式"><a class="markdownIt-Anchor" href="#消费方式">#</a> 消费方式</h2>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207183521.png" alt="20250207183521"></p>
<h2 id="消费总体流程"><a class="markdownIt-Anchor" href="#消费总体流程">#</a> 消费总体流程</h2>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207183800.png" alt="20250207183800"></p>
<p>offset 维护在系统主题中保存，老版本是维护在 zk 中，但是由于消费者需要与 zk 大量通信，新版本迁移到 broker 上的特殊主题当中</p>
<h2 id="消费者组原理"><a class="markdownIt-Anchor" href="#消费者组原理">#</a> 消费者组原理</h2>
<h3 id="消费者组初始化流程"><a class="markdownIt-Anchor" href="#消费者组初始化流程">#</a> 消费者组初始化流程</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207185811.png" alt="20250207185811"></p>
<ol>
<li>首先确认消费者组的 coordinator，即哪个 broker 上的 coordinator 负责管理该消费者组，由 groupid 的 hashcode%50 计算得出</li>
<li>消费者组中的消费者向 coordinator 发送 joinGroup 请求，coordinator 选举消费者组的一个 cosumer 作为消费 leader</li>
<li>coordinator 将消费的 topic 概况发送给 consumer leader</li>
<li>consumer leader 负责制定当前消费者组的消费方案并上报给 coordinator</li>
<li>coordinator 将消费方案下发给各个消费者</li>
<li>消费者组中的消费者与 coordinator 进行 rebalance，若超时消费或者心跳丢失就触发消费者组之间的再平衡</li>
</ol>
<h3 id="消费者组详细消费流程"><a class="markdownIt-Anchor" href="#消费者组详细消费流程">#</a> 消费者组详细消费流程</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207190338.png" alt="20250207190338"><br>
consumer 启动 consumerNetworkClient，并按照批次大小或时间间隔向 broker 发送拉取请求，并基于回调函数拉取数据，然后经过反序列化、拦截器、最终处理数据</p>
<h3 id="消费者分区分配再平衡"><a class="markdownIt-Anchor" href="#消费者分区分配再平衡">#</a> 消费者分区分配再平衡</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207193718.png" alt="20250207193718"></p>
<ol>
<li>
<p>range 分配策略针对一个 topic 而言<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207193830.png" alt="20250207193830"></p>
</li>
<li>
<p>roundrobin 分配策略针对所有 topic 而言<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207194314.png" alt="20250207194314"></p>
</li>
<li>
<p>sticky 分配策略： 尽量均匀又随机<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207194607.png" alt="20250207194607"></p>
</li>
</ol>
<h3 id="offset位置"><a class="markdownIt-Anchor" href="#offset位置">#</a> offset 位置</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207194919.png" alt="20250207194919"></p>
<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic + 分区号，value 就是当前 offset 的值。<br>
每隔一段时间，kafka 内部会对这个 topic 进行 compact 压缩存储，也就是每个 group.id+topic + 分区号就保留最新数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server hadoop102:9092 --consumer.config config/consumer.properties --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageForm atter&quot; --from-beginning</span><br></pre></td></tr></table></figure>
<p>为了使我们能够专注于自己的业务逻辑，kafka 提供了自动提交 offset 的功能。<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207195252.png" alt="20250207195252"></p>
<p>手动提交：<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207195440.png" alt="20250207195440"></p>
<p>指定 offset 位置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">  kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">  assignment = kafkaConsumer.assignment();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (TopicPartition tp: assignment) &#123;  <span class="comment">// 遍历所有分区，并指定 offset 从 1700 的位置开始消费</span></span><br><span class="line">  kafkaConsumer.seek(tp, <span class="number">1700</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>指定时间消费：将时间转化成对应 offset</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">  kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">  assignment = kafkaConsumer.assignment();</span><br><span class="line">&#125;</span><br><span class="line">HashMap&lt;TopicPartition, Long&gt; timestampToSearch = <span class="keyword">new</span></span><br><span class="line"><span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;  <span class="comment">// 封装集合存储，每个分区对应一天前的数据</span></span><br><span class="line">  timestampToSearch.put(topicPartition,</span><br><span class="line">  System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = kafkaConsumer.offsetsForTimes(timestampToSearch); <span class="comment">// 获取从 1 天前开始消费的每个分区的 offset</span></span><br><span class="line"><span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;   <span class="comment">// 遍历每个分区，对每个分区设置消费时间。</span></span><br><span class="line">  <span class="type">OffsetAndTimestamp</span> <span class="variable">offsetAndTimestamp</span> <span class="operator">=</span> offsets.get(topicPartition);  <span class="comment">// 根据时间指定开始消费的位置</span></span><br><span class="line">  <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>)&#123;</span><br><span class="line">    kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="消费者事务"><a class="markdownIt-Anchor" href="#消费者事务">#</a> 消费者事务</h3>
<p><img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207200506.png" alt="20250207200506"><br>
 为解决重复消费和漏消费的问题，采用消费者事务<br>
<img data-src="https://raw.githubusercontent.com/euanpic8888/images/main/images20250207200654.png" alt="20250207200654"></p>
<h3 id="章节小结-2"><a class="markdownIt-Anchor" href="#章节小结-2">#</a> 章节小结</h3>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXZyNHkxNjc3az9zcG1faWRfZnJvbT0zMzMuNzg4LnBsYXllci5zd2l0Y2gmYW1wO3ZkX3NvdXJjZT0xN2E1Mzk4MDg2NDU1ZjdmMWQwMDdkZjM4MmVhYjM5NSZhbXA7cD01OQ==">章节小结</span></p>

  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2025-02-07 20:54:09" itemprop="dateModified" datetime="2025-02-07T20:54:09+08:00">2025-02-07</time>
  </span>
  <span id="2025/02/06/kafka/" class="item leancloud_visitors" data-flag-title="Kafka Notes" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 赞赏</button>
  <p>请我喝[茶]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechat.png" alt="Euan Cai 微信支付">
        <p>微信支付</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>Euan Cai <i class="ic i-at"><em>@</em></i>Kanseaveg's Domain
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="https://blog.chatdb.cc/2025/02/06/kafka/" title="Kafka Notes">https://blog.chatdb.cc/2025/02/06/kafka/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
    </div>
    <div class="item right">
    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka"><span class="toc-number">1.</span> <span class="toc-text"> kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.</span> <span class="toc-text"> 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81"><span class="toc-number">1.2.</span> <span class="toc-text"> 为什么需要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">1.3.</span> <span class="toc-text"> 集群部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E4%BA%92%E5%91%BD%E4%BB%A4"><span class="toc-number">1.4.</span> <span class="toc-text"> 交互命令</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka-%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text"> kafka 的架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">3.</span> <span class="toc-text"> kafka 生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text"> 生产者发送消息原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%97%B6%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">3.2.</span> <span class="toc-text"> 生产者发送时的分区策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E5%90%9E%E5%90%90%E9%87%8F%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95"><span class="toc-number">3.3.</span> <span class="toc-text"> 生产者发送吞吐量提升方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7ack%E5%BA%94%E7%AD%94%E7%BA%A7%E5%88%AB"><span class="toc-number">3.4.</span> <span class="toc-text"> 生产者如何保证数据可靠性（ACK 应答级别）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D"><span class="toc-number">3.5.</span> <span class="toc-text"> 生产者如何保证数据去重</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">3.5.1.</span> <span class="toc-text"> 数据幂等性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="toc-number">3.5.2.</span> <span class="toc-text"> 生产者事务</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka-broker"><span class="toc-number">4.</span> <span class="toc-text"> kafka broker</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka-broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text"> kafka broker 工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#zk%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84kafka%E4%BF%A1%E6%81%AF"><span class="toc-number">4.1.1.</span> <span class="toc-text"> zk 中存储的 kafka 信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#broker%E4%B8%8Ezk%E5%8D%8F%E8%B0%83%E7%9A%84%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.2.</span> <span class="toc-text"> broker 与 zk 协调的总体工作流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E6%9C%8D%E5%BD%B9%E4%B8%8E%E9%80%80%E5%BD%B9"><span class="toc-number">4.2.</span> <span class="toc-text"> 节点服役与退役</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#broker%E6%9C%8D%E5%BD%B9%E4%B8%8E%E9%80%80%E5%BD%B9"><span class="toc-number">4.2.1.</span> <span class="toc-text"> broker 服役与退役</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AB%A0%E8%8A%82%E5%B0%8F%E7%BB%93"><span class="toc-number">4.2.2.</span> <span class="toc-text"> 章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka-%E5%89%AF%E6%9C%AC"><span class="toc-number">4.3.</span> <span class="toc-text"> kafka 副本</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#leader%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">4.3.1.</span> <span class="toc-text"> leader 选举流程（演示）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#follower%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%BC%94%E7%A4%BA"><span class="toc-number">4.3.2.</span> <span class="toc-text"> follower 故障处理（演示）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#leader%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%BC%94%E7%A4%BA"><span class="toc-number">4.3.3.</span> <span class="toc-text"> leader 故障处理（演示）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="toc-number">4.4.</span> <span class="toc-text"> kafka 文件存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">4.4.1.</span> <span class="toc-text"> 文件存储机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86"><span class="toc-number">4.4.2.</span> <span class="toc-text"> 文件清理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99"><span class="toc-number">4.5.</span> <span class="toc-text"> kafka 如何实现高效读写</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">5.</span> <span class="toc-text"> kafka 消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F"><span class="toc-number">5.1.</span> <span class="toc-text"> 消费方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">5.2.</span> <span class="toc-text"> 消费总体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%8E%9F%E7%90%86"><span class="toc-number">5.3.</span> <span class="toc-text"> 消费者组原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B"><span class="toc-number">5.3.1.</span> <span class="toc-text"> 消费者组初始化流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%AF%A6%E7%BB%86%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B"><span class="toc-number">5.3.2.</span> <span class="toc-text"> 消费者组详细消费流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">5.3.3.</span> <span class="toc-text"> 消费者分区分配再平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#offset%E4%BD%8D%E7%BD%AE"><span class="toc-number">5.3.4.</span> <span class="toc-text"> offset 位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="toc-number">5.3.5.</span> <span class="toc-text"> 消费者事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AB%A0%E8%8A%82%E5%B0%8F%E7%BB%93-2"><span class="toc-number">5.3.6.</span> <span class="toc-text"> 章节小结</span></a></li></ol></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Euan Cai"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">Euan Cai</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">1</span>
        <span class="name">文章</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2thbnNlYXZlZw==" title="https:&#x2F;&#x2F;github.com&#x2F;kanseaveg"><i class="ic i-github"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/2025/02/06/kafka/" title="Kafka Notes">Kafka Notes</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Euan Cai @ Kanseaveg's Domain</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2025/02/06/kafka/',
    favicon: {
      show: "（●´3｀●）やれやれだぜ",
      hide: "(´Д｀)大変だ！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,
    copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
